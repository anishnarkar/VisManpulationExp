{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0027cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f6b6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Load libraries for the U-net Model\n",
    "\n",
    "\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import backend as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2580358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filter_size, size, stride, batch_norm=False, multiple=False):\n",
    "    \n",
    "    conv = layers.Conv1D(size, filter_size, strides = stride, padding=\"same\", kernel_initializer = 'he_normal')(x)\n",
    "    if multiple:\n",
    "        conv = layers.Conv1D(size, filter_size, strides = stride, padding=\"same\", kernel_initializer = 'he_normal')(x)\n",
    "        conv = layers.Conv1D(size, filter_size, strides = stride, padding=\"same\", kernel_initializer = 'he_normal')(x)\n",
    "            \n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization()(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176b8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oleg_model(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
    "    inputs1 = layers.Input(input_shape, dtype=tf.float32)\n",
    "    \n",
    "    block_1 = conv_block(inputs1, 3, 64, 1, batch_norm=True)\n",
    "    block_2 = conv_block(block_1, 3, 64, 1, batch_norm=True, multiple=True)\n",
    "    block_3 = conv_block(block_2, 3, 128, 1, batch_norm=True)\n",
    "    block_4 = conv_block(block_3, 3, 128, 1, batch_norm=True, multiple=True)\n",
    "    block_5 = conv_block(block_4, 3, 256, 1, batch_norm=True)\n",
    "    block_6 = conv_block(block_5, 3, 256, 1, batch_norm=True, multiple=True)\n",
    "    block_7 = conv_block(block_6, 3, 512, 1, batch_norm=True)\n",
    "    block_8 = conv_block(block_7, 3, 512, 1, batch_norm=True, multiple=True)\n",
    "    \n",
    "    average_pooling = AveragePooling1D(pool_size=2, strides=2, padding='same')(block_8)\n",
    "    flatten = tf.reshape(average_pooling,[-1])\n",
    "    oleg_final = layers.Dense(1, activation = \"linear\")(average_pooling)\n",
    "    \n",
    "    model = models.Model(inputs1, oleg_final, name=\"Oleg_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "225ab93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_block(x, size, multiple=False):\n",
    "    \n",
    "    conv = layers.LSTM(size, activation = 'relu', input_shape=(1500,2), kernel_initializer = 'he_normal')(x)\n",
    "    if multiple:\n",
    "        conv = layers.LSTM(size, activation = 'relu', input_shape=(1500,2), kernel_initializer = 'he_normal')(x)\n",
    "        conv = layers.LSTM(size, activation = 'relu', input_shape=(1500,2), kernel_initializer = 'he_normal')(x)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "621efb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape, NUM_CLASSES=1, dropout_rate=0.0):\n",
    "    inputs1 = layers.Input(input_shape, dtype=tf.float32)\n",
    "    block_1 = lstm_block(inputs1,  64)\n",
    "    block_2 = lstm_block(block_1,  64, multiple=True)\n",
    "    block_3 = lstm_block(block_2,  128)\n",
    "    block_4 = lstm_block(block_3,  128, multiple=True)\n",
    "    block_5 = lstm_block(block_4,  256)\n",
    "    block_6 = lstm_block(block_5,  256, multiple=True)\n",
    "    block_7 = lstm_block(block_6,  512)\n",
    "    block_8 = lstm_block(block_7,  512, multiple=True)\n",
    "    \n",
    "    dense_1 = layers.Dense(1, activation = 'linear')(block_8)\n",
    "    model = models.Model(inputs1, dense_1, name=\"Oleg_Model\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1895a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_oleg_model(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
    "    inputs1 = layers.Input(input_shape, dtype=tf.float32)\n",
    "    \n",
    "    block_1_a = conv_block(inputs1, 3, 64, 1, batch_norm=True)\n",
    "    block_2_a = conv_block(block_1_a, 3, 64, 1, batch_norm=True, multiple=True)\n",
    "    block_3_a = conv_block(block_2_a, 3, 128, 1, batch_norm=True)\n",
    "    block_4_a = conv_block(block_3_a, 3, 128, 1, batch_norm=True, multiple=True)\n",
    "    average_pooling_a = AveragePooling1D(pool_size=2, strides=2, padding='same')(block_4_a)\n",
    "    flatten_a = layers.Flatten()(average_pooling_a)\n",
    "    \n",
    "    block_1_b = conv_block(inputs1, 5, 64, 1, batch_norm=True)\n",
    "    block_2_b = conv_block(block_1_b, 5, 64, 1, batch_norm=True, multiple=True)\n",
    "    block_3_b = conv_block(block_2_b, 5, 128, 1, batch_norm=True)\n",
    "    block_4_b = conv_block(block_3_b, 5, 128, 1, batch_norm=True, multiple=True)\n",
    "    average_pooling_b = AveragePooling1D(pool_size=2, strides=2, padding='same')(block_4_b)\n",
    "    flatten_b = layers.Flatten()(average_pooling_b)\n",
    "        \n",
    "    block_1_c = conv_block(inputs1, 7, 64, 1, batch_norm=True)\n",
    "    block_2_c = conv_block(block_1_c, 7, 64, 1, batch_norm=True, multiple=True)\n",
    "    block_3_c = conv_block(block_2_c, 7, 128, 1, batch_norm=True)\n",
    "    block_4_c = conv_block(block_3_c, 7, 128, 1, batch_norm=True, multiple=True)\n",
    "    average_pooling_c = AveragePooling1D(pool_size=2, strides=2, padding='same')(block_4_c)\n",
    "    flatten_c = layers.Flatten()(average_pooling_c)\n",
    "    \n",
    "    flatten = tf.keras.layers.concatenate([flatten_a, flatten_b, flatten_c])\n",
    "    oleg_final = layers.Dense(100, activation = \"relu\")(flatten)\n",
    "    oleg_final = layers.Dense(1, activation = \"relu\")(oleg_final)\n",
    "    \n",
    "    model = models.Model(inputs1, oleg_final, name=\"Multihead_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cd94e43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model = oleg_model(input_shape = (2,1500))\n",
    "# model = multihead_oleg_model(input_shape = (2,1500))\n",
    "# model = lstm_model(input_shape = (2,1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42fc437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Oleg_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 2, 1500)]         0         \n",
      "                                                                 \n",
      " conv1d_200 (Conv1D)         (None, 2, 64)             288064    \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 2, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_100 (Activation)  (None, 2, 64)            0         \n",
      "                                                                 \n",
      " conv1d_203 (Conv1D)         (None, 2, 64)             12352     \n",
      "                                                                 \n",
      " batch_normalization_101 (Ba  (None, 2, 64)            256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_101 (Activation)  (None, 2, 64)            0         \n",
      "                                                                 \n",
      " conv1d_204 (Conv1D)         (None, 2, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_102 (Ba  (None, 2, 128)           512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_102 (Activation)  (None, 2, 128)           0         \n",
      "                                                                 \n",
      " conv1d_207 (Conv1D)         (None, 2, 128)            49280     \n",
      "                                                                 \n",
      " batch_normalization_103 (Ba  (None, 2, 128)           512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_103 (Activation)  (None, 2, 128)           0         \n",
      "                                                                 \n",
      " conv1d_208 (Conv1D)         (None, 2, 256)            98560     \n",
      "                                                                 \n",
      " batch_normalization_104 (Ba  (None, 2, 256)           1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_104 (Activation)  (None, 2, 256)           0         \n",
      "                                                                 \n",
      " conv1d_211 (Conv1D)         (None, 2, 256)            196864    \n",
      "                                                                 \n",
      " batch_normalization_105 (Ba  (None, 2, 256)           1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_105 (Activation)  (None, 2, 256)           0         \n",
      "                                                                 \n",
      " conv1d_212 (Conv1D)         (None, 2, 512)            393728    \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  (None, 2, 512)           2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_106 (Activation)  (None, 2, 512)           0         \n",
      "                                                                 \n",
      " conv1d_215 (Conv1D)         (None, 2, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  (None, 2, 512)           2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_107 (Activation)  (None, 2, 512)           0         \n",
      "                                                                 \n",
      " average_pooling1d_24 (Avera  (None, 1, 512)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1, 1)              513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,858,689\n",
      "Trainable params: 1,854,849\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa222f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('train_eptad_data.npy')\n",
    "y_train = np.load('train_eptad_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49adf887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-41.167292,  90.      ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(X_train[:,1,:], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1303986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffde4232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('float64'), dtype('int64'), dtype('int64'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype, X_val.dtype, y_train.dtype, y_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f23fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "130988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "?tf.keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5432f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143988"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 0].shape[0] + y_train[y_train != 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be551846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143988,), (143988, 2, 1500))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dced3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "dropout= 0\n",
    "lr = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbdeb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "model_name = 'OLEG_model_kernel_size=' + str(k) + '_dropout=' + str(dropout) + '_lr=' + str(lr)\n",
    "model_checkpoint = ModelCheckpoint('D:/ETPAD.v2/models/' + model_name + '.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "# Early Stop\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience= 15,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "scheduler_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Tensorboard\n",
    "log_dir = r\"D:\\ETPAD.v2\\logs\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e41f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eab372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size = 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
